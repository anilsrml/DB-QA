#  Ollama ile Lokal Model KullanÄ±mÄ±

Bu kÄ±lavuz, projeyi Ollama ile lokal modeller kullanarak Ã§alÄ±ÅŸtÄ±rmanÄ±zÄ± saÄŸlar.

##  Avantajlar

âœ… **Tamamen Lokal** - Ä°nternet baÄŸlantÄ±sÄ± gerekmez  
âœ… **Ãœcretsiz** - API key gerekmez  
âœ… **Gizlilik** - Verileriniz dÄ±ÅŸarÄ± Ã§Ä±kmaz  
âœ… **HÄ±zlÄ±** - Lokal Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in hÄ±zlÄ±  
âœ… **Ã‡oklu Model** - Mistral, Llama, Phi, vs.

## ğŸ“¥ AdÄ±m 1: Ollama Kurulumu

### Windows

1. [Ollama Ä°ndir](https://ollama.ai/download/windows)
2. `OllamaSetup.exe` dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n
3. Kurulum otomatik tamamlanacak
4. Ollama arka planda Ã§alÄ±ÅŸmaya baÅŸlayacak

### Linux

```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### macOS

```bash
brew install ollama
```

### Kurulumu Kontrol Edin

```powershell
ollama --version
```

##  AdÄ±m 2: Model Ä°ndirme

### Ã–nerilen Modeller

```powershell
# Mistral (Ã–nerilen - HÄ±zlÄ± ve iyi)
ollama pull mistral

# Llama 3.2 (Daha gÃ¼Ã§lÃ¼)
ollama pull llama3.2

# Llama 3.2 3B (Daha hafif, hÄ±zlÄ±)
ollama pull llama3.2:3b

# Phi 3 (Microsoft - Hafif)
ollama pull phi3

# Gemma 2 (Google - Orta)
ollama pull gemma2
```

### Model Listesini GÃ¶rÃ¼ntÃ¼leme

```powershell
ollama list
```

**Ã‡Ä±ktÄ±:**
```
NAME              ID              SIZE      MODIFIED
mistral:latest    abc123...       4.1 GB    2 days ago
llama3.2:latest   def456...       2.0 GB    1 day ago
```

##  AdÄ±m 3: Proje KonfigÃ¼rasyonu

### .env DosyasÄ±nÄ± DÃ¼zenleyin

```powershell
notepad .env
```

Åu satÄ±rlarÄ± ekleyin/dÃ¼zenleyin:

```env
# LLM Provider: "ollama" veya "gemini"
LLM_PROVIDER=ollama

# Ollama AyarlarÄ±
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# Gemini artÄ±k gerekli deÄŸil (opsiyonel)
# GOOGLE_API_KEY=...

# PostgreSQL ayarlarÄ± (deÄŸiÅŸmedi)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ecommerce_db
DB_USER=postgres
DB_PASSWORD=your_password_here

MAX_QUERY_TIMEOUT=30
MAX_RESULT_ROWS=1000
LOG_LEVEL=INFO
```

##  AdÄ±m 4: Projeyi Ã‡alÄ±ÅŸtÄ±rÄ±n

```powershell
# Test edin
python main.py test

# Ã‡alÄ±ÅŸtÄ±rÄ±n
python main.py
```

##  Model DeÄŸiÅŸtirme

FarklÄ± modeller denemek iÃ§in `.env` dosyasÄ±nÄ± dÃ¼zenleyin:

```env
# Mistral kullan
OLLAMA_MODEL=mistral

# Llama 3.2 kullan
OLLAMA_MODEL=llama3.2

# Llama 3.2 3B kullan (daha hÄ±zlÄ±)
OLLAMA_MODEL=llama3.2:3b

# Phi 3 kullan
OLLAMA_MODEL=phi3
```

DeÄŸiÅŸtirdikten sonra projeyi yeniden baÅŸlatÄ±n.

##  Gemini kullanÄ±mÄ±

Ollama yerine  Gemini kullanmak isterseniz:

```env
LLM_PROVIDER=gemini
GOOGLE_API_KEY=your_api_key_here
```


