# ğŸ¦™ Ollama ile Lokal Model KullanÄ±mÄ±

Bu kÄ±lavuz, projeyi Ollama ile lokal modeller kullanarak Ã§alÄ±ÅŸtÄ±rmanÄ±zÄ± saÄŸlar.

## ğŸ¯ Avantajlar

âœ… **Tamamen Lokal** - Ä°nternet baÄŸlantÄ±sÄ± gerekmez  
âœ… **Ãœcretsiz** - API key gerekmez  
âœ… **Gizlilik** - Verileriniz dÄ±ÅŸarÄ± Ã§Ä±kmaz  
âœ… **HÄ±zlÄ±** - Lokal Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in hÄ±zlÄ±  
âœ… **Ã‡oklu Model** - Mistral, Llama, Phi, vs.

## ğŸ“¥ AdÄ±m 1: Ollama Kurulumu

### Windows

1. [Ollama Ä°ndir](https://ollama.ai/download/windows)
2. `OllamaSetup.exe` dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n
3. Kurulum otomatik tamamlanacak
4. Ollama arka planda Ã§alÄ±ÅŸmaya baÅŸlayacak

### Linux

```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### macOS

```bash
brew install ollama
```

### Kurulumu Kontrol Edin

```powershell
ollama --version
```

## ğŸ¤– AdÄ±m 2: Model Ä°ndirme

### Ã–nerilen Modeller

```powershell
# Mistral (Ã–nerilen - HÄ±zlÄ± ve iyi)
ollama pull mistral

# Llama 3.2 (Daha gÃ¼Ã§lÃ¼)
ollama pull llama3.2

# Llama 3.2 3B (Daha hafif, hÄ±zlÄ±)
ollama pull llama3.2:3b

# Phi 3 (Microsoft - Hafif)
ollama pull phi3

# Gemma 2 (Google - Orta)
ollama pull gemma2
```

### Model Listesini GÃ¶rÃ¼ntÃ¼leme

```powershell
ollama list
```

**Ã‡Ä±ktÄ±:**
```
NAME              ID              SIZE      MODIFIED
mistral:latest    abc123...       4.1 GB    2 days ago
llama3.2:latest   def456...       2.0 GB    1 day ago
```

## âš™ï¸ AdÄ±m 3: Proje KonfigÃ¼rasyonu

### .env DosyasÄ±nÄ± DÃ¼zenleyin

```powershell
notepad .env
```

Åu satÄ±rlarÄ± ekleyin/dÃ¼zenleyin:

```env
# LLM Provider: "ollama" veya "gemini"
LLM_PROVIDER=ollama

# Ollama AyarlarÄ±
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# Gemini artÄ±k gerekli deÄŸil (opsiyonel)
# GOOGLE_API_KEY=...

# PostgreSQL ayarlarÄ± (deÄŸiÅŸmedi)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ecommerce_db
DB_USER=postgres
DB_PASSWORD=your_password_here

MAX_QUERY_TIMEOUT=30
MAX_RESULT_ROWS=1000
LOG_LEVEL=INFO
```

## ğŸš€ AdÄ±m 4: Projeyi Ã‡alÄ±ÅŸtÄ±rÄ±n

```powershell
# Test edin
python main.py test

# Ã‡alÄ±ÅŸtÄ±rÄ±n
python main.py
```

## ğŸ”„ Model DeÄŸiÅŸtirme

FarklÄ± modeller denemek iÃ§in `.env` dosyasÄ±nÄ± dÃ¼zenleyin:

```env
# Mistral kullan
OLLAMA_MODEL=mistral

# Llama 3.2 kullan
OLLAMA_MODEL=llama3.2

# Llama 3.2 3B kullan (daha hÄ±zlÄ±)
OLLAMA_MODEL=llama3.2:3b

# Phi 3 kullan
OLLAMA_MODEL=phi3
```

DeÄŸiÅŸtirdikten sonra projeyi yeniden baÅŸlatÄ±n.

## ğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model | Boyut | HÄ±z | Kalite | RAM |
|-------|-------|-----|--------|-----|
| **mistral** | 4.1 GB | âš¡âš¡âš¡ | ğŸ§ ğŸ§ ğŸ§  | 8 GB |
| **llama3.2** | 2.0 GB | âš¡âš¡ | ğŸ§ ğŸ§ ğŸ§ ğŸ§  | 8 GB |
| **llama3.2:3b** | 2.0 GB | âš¡âš¡âš¡âš¡ | ğŸ§ ğŸ§  | 4 GB |
| **phi3** | 2.3 GB | âš¡âš¡âš¡ | ğŸ§ ğŸ§ ğŸ§  | 4 GB |
| **gemma2** | 5.4 GB | âš¡âš¡ | ğŸ§ ğŸ§ ğŸ§  | 8 GB |

## ğŸ¯ Hangi Modeli SeÃ§meliyim?

### BilgisayarÄ±nÄ±z GÃ¼Ã§lÃ¼yse (16GB+ RAM)
```env
OLLAMA_MODEL=llama3.2
```
En iyi kalite, orta hÄ±z.

### HÄ±z Ã–ncelikliyse
```env
OLLAMA_MODEL=llama3.2:3b
```
veya
```env
OLLAMA_MODEL=mistral
```

### RAM SÄ±nÄ±rlÄ±ysa (8GB)
```env
OLLAMA_MODEL=phi3
```

### TÃ¼rkÃ§e Ä°Ã§in En Ä°yisi
```env
OLLAMA_MODEL=mistral
```
Mistral, TÃ¼rkÃ§e'de Ã§ok iyi performans gÃ¶sterir.

## ğŸ”§ Sorun Giderme

### Hata: "Ollama connection refused"

**Ã‡Ã¶zÃ¼m:** Ollama Ã§alÄ±ÅŸmÄ±yor

```powershell
# Windows'ta Ollama'yÄ± baÅŸlat
ollama serve
```

Yeni bir terminal aÃ§Ä±n ve projeyi Ã§alÄ±ÅŸtÄ±rÄ±n.

### Hata: "Model not found"

**Ã‡Ã¶zÃ¼m:** Model indirilmemiÅŸ

```powershell
ollama pull mistral
```

### Hata: "Out of memory"

**Ã‡Ã¶zÃ¼m:** Daha kÃ¼Ã§Ã¼k bir model kullanÄ±n

```env
OLLAMA_MODEL=llama3.2:3b
```

### Ollama Ã‡alÄ±ÅŸÄ±yor mu Kontrol

```powershell
curl http://localhost:11434
```

**Beklenen Ã§Ä±ktÄ±:**
```
Ollama is running
```

## ğŸŒ Gemini'ye Geri DÃ¶nme

Ollama yerine tekrar Gemini kullanmak isterseniz:

```env
LLM_PROVIDER=gemini
GOOGLE_API_KEY=your_api_key_here
```

## ğŸ“ˆ Performans Ä°puÃ§larÄ±

1. **GPU KullanÄ±mÄ±**: Ollama otomatik GPU kullanÄ±r (NVIDIA/AMD)
2. **RAM**: Model boyutundan 2x RAM olmalÄ±
3. **Ä°lk Sorgu**: Ä°lk sorgu yavaÅŸ olabilir (model yÃ¼kleniyor)
4. **Sonraki Sorgular**: Ã‡ok hÄ±zlÄ± (model bellekte)

## ğŸ¨ Ã–rnek KullanÄ±m

```
Soru: KaÃ§ mÃ¼ÅŸterimiz var?

[Ollama - Mistral]
âœ… BaÅŸarÄ±lÄ±!

SQL: SELECT COUNT(*) as musteri_sayisi FROM customers;

VeritabanÄ±nda toplam 10 mÃ¼ÅŸteri bulunmaktadÄ±r.

GÃ¼ven: 95% | SatÄ±r: 1
âš¡ Tamamen lokal Ã§alÄ±ÅŸtÄ± - Ä°nternet kullanÄ±lmadÄ±!
```

## ğŸ†š Ollama vs Gemini

| Ã–zellik | Ollama | Gemini |
|---------|--------|--------|
| **Maliyet** | Ãœcretsiz | API limiti var |
| **Ä°nternet** | Gerekmez | Gerekir |
| **Gizlilik** | %100 lokal | Cloud'a gider |
| **HÄ±z** | Ã‡ok hÄ±zlÄ± | Orta (aÄŸa baÄŸlÄ±) |
| **Kalite** | Ä°yi-Ã‡ok iyi | MÃ¼kemmel |
| **Kurulum** | Kolay | Sadece API key |

## ğŸ¯ SonuÃ§

Ollama ile:
- âœ… Tamamen Ã¼cretsiz
- âœ… Tamamen lokal
- âœ… Gizlilik korunur
- âœ… Ä°nternet gerekmez
- âœ… HÄ±zlÄ± Ã§alÄ±ÅŸÄ±r

BaÅŸarÄ±lar! ğŸš€

